# Estudando Rust e a biblioteca playwrigth em Rust

> ## Objetivo de criar spiders e bots com a bilblioteca playwrigth , para automatizar tarefas e coletar dados de sites web

[!] Estudando paginas dinamicas com javascript - tentativa de capturar elementos e seletores renderizados com javascript (src\bin: arquivo main.rs e new_main.rs)

    - parcialmente conseguido, consigo navegar por elementos e até salvar paginas em .png, os seletores estão correto, PRECISO agora implementar e testar lógica anti-detecção.

    - verificar como pode ser melhor usar Xpaths ao inves de seletores, conforme dica recebida

    [ ] Tentar mudar para outros links, estudar outras features, como buscas no tiktok

[x] Navegação web - clicks e preenchimentos de formularios e campos textfield (arquivo spider_exemplo.rs)

[ ] Coleta de dados - captura de dados de sites web, como preços, produtos e salvar em um JSON (arquivo spider.rs)

[ ] Integração com APIs - integração com APIs para coletar dados de terceiros

[ ] Testes de usabilidade - testes de usabilidade para garantir que os bots estão funcionando corretamente - estudo de tratamento de erros

[ ] Criando bots para automatizar tarefas - bots para automatizar tarefas como login
